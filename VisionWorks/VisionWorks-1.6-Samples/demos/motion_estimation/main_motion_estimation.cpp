/*
# Copyright (c) 2014-2016, NVIDIA CORPORATION. All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions
# are met:
#  * Redistributions of source code must retain the above copyright
#    notice, this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.
#  * Neither the name of NVIDIA CORPORATION nor the names of its
#    contributors may be used to endorse or promote products derived
#    from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
# PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
# CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
# EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
# PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
# PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
# OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*/

#include <iostream>
#include <sstream>
#include <iomanip>
#include <string>
#include <memory>

#include <NVX/nvx.h>
#include <NVX/nvx_timer.hpp>

#include "NVX/Application.hpp"
#include "NVX/ConfigParser.hpp"
#include "OVX/FrameSourceOVX.hpp"
#include "OVX/RenderOVX.hpp"
#include "NVX/SyncTimer.hpp"
#include "OVX/UtilityOVX.hpp"

#include "iterative_motion_estimator.hpp"

//
// Process events
//

struct EventData
{
    EventData() : stop(false), pause(false) {}

    bool stop;
    bool pause;
};


static void keyboardEventCallback(void* eventData, vx_char key, vx_uint32, vx_uint32)
{
    EventData* data = static_cast<EventData*>(eventData);

    if (key == 27) // escape
    {
        data->stop = true;
    }
    else if (key == ' ') // space
    {
        data->pause = !data->pause;
    }
}

//
// Parse configuration file
//

static bool read(const std::string& configFile,
                 IterativeMotionEstimator::Params& params,
                 std::string& message)
{
    std::unique_ptr<nvxio::ConfigParser> parser(nvxio::createConfigParser());

    parser->addParameter("biasWeight", nvxio::OptionHandler::real(&params.biasWeight,
             nvxio::ranges::atLeast(0.0f)));
    parser->addParameter("mvDivFactor", nvxio::OptionHandler::integer(&params.mvDivFactor,
             nvxio::ranges::atLeast(0) & nvxio::ranges::atMost(16)));
    parser->addParameter("smoothnessFactor", nvxio::OptionHandler::real(&params.smoothnessFactor,
             nvxio::ranges::atLeast(0.0f)));

    message = parser->parse(configFile);

    return message.empty();
}

//
// main - Application entry point
//

int main(int argc, char** argv)
{
    try
    {
        nvxio::Application &app = nvxio::Application::get();
        ovxio::printVersionInfo();

        //
        // Parse command line arguments
        //

        std::string sourceUri = app.findSampleFilePath("pedestrians.mp4");
        std::string configFile = app.findSampleFilePath("motion_estimation_demo_config.ini");

        app.setDescription("This sample demonstrates Iterative Motion Estimation algorithm");
        app.addOption('s', "source", "Source URI", nvxio::OptionHandler::string(&sourceUri));
        app.addOption('c', "config", "Config file path", nvxio::OptionHandler::string(&configFile));
        app.init(argc, argv);

        //
        // Reads and checks input parameters
        //

        IterativeMotionEstimator::Params params;
        std::string error;
        if (!read(configFile, params, error))
        {
            std::cout << error;
            return nvxio::Application::APP_EXIT_CODE_INVALID_VALUE;
        }

        //
        // Create OpenVX context
        //

        ovxio::ContextGuard context;
        vxDirective(context, VX_DIRECTIVE_ENABLE_PERFORMANCE);

        //
        // Messages generated by the OpenVX framework will be processed by ovxio::stdoutLogCallback
        //

        vxRegisterLogCallback(context, &ovxio::stdoutLogCallback, vx_false_e);

        //
        // Create a Frame Source
        //

        std::unique_ptr<ovxio::FrameSource> frameSource(ovxio::createDefaultFrameSource(context, sourceUri));

        if (!frameSource || !frameSource->open())
        {
            std::cerr << "Error: cannot open frame source!" << std::endl;
            return nvxio::Application::APP_EXIT_CODE_NO_RESOURCE;
        }

        if (frameSource->getSourceType() == ovxio::FrameSource::SINGLE_IMAGE_SOURCE)
        {
            std::cerr << "Can't work on a single image." << std::endl;
            return nvxio::Application::APP_EXIT_CODE_INVALID_FORMAT;
        }

        ovxio::FrameSource::Parameters frameConfig = frameSource->getConfiguration();

        //
        // Create a Render
        //

        std::unique_ptr<ovxio::Render> render = ovxio::createDefaultRender(context, "Motion Estimation Demo",
                                                                           frameConfig.frameWidth, frameConfig.frameHeight);

        if (!render)
        {
            std::cerr << "Error: Cannot create render!" << std::endl;
            return nvxio::Application::APP_EXIT_CODE_NO_RENDER;
        }

        EventData eventData;
        render->setOnKeyboardEventCallback(keyboardEventCallback, &eventData);

        //
        // Create OpenVX Image to hold frames from video source
        //

        vx_image frameExemplar = vxCreateImage(context,
            frameConfig.frameWidth, frameConfig.frameHeight, VX_DF_IMAGE_RGBX);
        NVXIO_CHECK_REFERENCE(frameExemplar);
        vx_delay frame_delay = vxCreateDelay(context, (vx_reference)frameExemplar, 2);
        NVXIO_CHECK_REFERENCE(frame_delay);
        vxReleaseImage(&frameExemplar);

        vx_image prevFrame = (vx_image)vxGetReferenceFromDelay(frame_delay, -1);
        vx_image currFrame = (vx_image)vxGetReferenceFromDelay(frame_delay, 0);

        //
        // Create algorithm
        //

        IterativeMotionEstimator ime(context);

        ovxio::FrameSource::FrameStatus frameStatus;
        do
        {
            frameStatus = frameSource->fetch(prevFrame);
        } while (frameStatus == ovxio::FrameSource::TIMEOUT);
        if (frameStatus == ovxio::FrameSource::CLOSED)
        {
            std::cerr << "Source has no frames" << std::endl;
            return nvxio::Application::APP_EXIT_CODE_NO_FRAMESOURCE;
        }

        ime.init(prevFrame, currFrame, params);

        //
        // Main loop
        //

        std::unique_ptr<nvxio::SyncTimer> syncTimer = nvxio::createSyncTimer();
        syncTimer->arm(1. / app.getFPSLimit());

        nvx::Timer totalTimer;
        totalTimer.tic();
        double proc_ms = 0;
        while (!eventData.stop)
        {
            if (!eventData.pause)
            {
                //
                // Grab next frame
                //

                frameStatus = frameSource->fetch(currFrame);

                if (frameStatus == ovxio::FrameSource::TIMEOUT)
                    continue;

                if (frameStatus == ovxio::FrameSource::CLOSED)
                {
                    if (!frameSource->open())
                    {
                        std::cerr << "Failed to reopen the source" << std::endl;
                        break;
                    }

                    do
                    {
                        frameStatus = frameSource->fetch(prevFrame);
                    } while (frameStatus == ovxio::FrameSource::TIMEOUT);
                    if (frameStatus == ovxio::FrameSource::CLOSED)
                    {
                        std::cerr << "Source has no frames" << std::endl;
                        return nvxio::Application::APP_EXIT_CODE_NO_FRAMESOURCE;
                    }

                    ime.init(prevFrame, currFrame, params);

                    continue;
                }

                //
                // Process
                //

                nvx::Timer procTimer;
                procTimer.tic();

                ime.process();

                proc_ms = procTimer.toc();
            }

            double total_ms = totalTimer.toc();

            std::cout << "Display Time : " << total_ms << " ms" << std::endl << std::endl;

            syncTimer->synchronize();

            total_ms = totalTimer.toc();

            totalTimer.tic();

            //
            // Show performance statistics
            //

            if (!eventData.pause)
            {
                ime.printPerfs();
            }

            //
            // Render
            //

            render->putImage(prevFrame);

            ovxio::Render::MotionFieldStyle mfStyle = {
                {  0u, 255u, 255u, 255u} // color
            };

            render->putMotionField(ime.getMotionField(), mfStyle);

            std::ostringstream msg;
            msg << std::fixed << std::setprecision(1);

            msg << "Resolution: " << frameConfig.frameWidth << 'x' << frameConfig.frameHeight << std::endl;
            msg << "Algorithm: " << proc_ms << " ms / " << 1000.0 / proc_ms << " FPS" << std::endl;
            msg << "Display: " << total_ms  << " ms / " << 1000.0 / total_ms << " FPS" << std::endl;
            msg << "Space - pause/resume" << std::endl;
            msg << "Esc - close the sample";

            ovxio::Render::TextBoxStyle textStyle = {
                {255u, 255u, 255u, 255u}, // color
                {0u,   0u,   0u, 127u}, // bgcolor
                {10u, 10u} // origin
            };

            render->putTextViewport(msg.str(), textStyle);

            if (!render->flush())
            {
                eventData.stop = true;
            }

            if (!eventData.pause)
            {
                vxAgeDelay(frame_delay);
            }
        }

        //
        // Release all objects
        //

        vxReleaseDelay(&frame_delay);
    }
    catch (const std::exception& e)
    {
        std::cerr << "Error: " << e.what() << std::endl;
        return nvxio::Application::APP_EXIT_CODE_ERROR;
    }

    return nvxio::Application::APP_EXIT_CODE_SUCCESS;
}
